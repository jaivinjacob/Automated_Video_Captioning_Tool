# Automated Video Captioning Tool

## Overview
The **Automated Video Captioning Tool** is a machine learning-powered application designed to generate **frame-by-frame captions** for videos, convert them into **audio descriptions**, and integrate them seamlessly for enhanced accessibility. This project leverages **deep learning models, video processing techniques, and natural language generation** to automate captioning and narration for videos.

---

## ğŸš€ Features
- **Frame-by-frame video captioning** using state-of-the-art **VIT-GPT2 and LSTM models**.
- **Audio description generation** using Google Text-to-Speech (TTS).
- **Silent part detection and synchronization** for seamless audio-visual integration.
- **Web-based interface** for user-friendly interactions.
- **Automated data processing and feature extraction** with ResNet50 and VIT models.

---

## ğŸ“ Project Structure

```
Automated_Video_Captioning_Tool/
â”‚-- FrontEnd/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ log-in.html
â”‚   â”œâ”€â”€ qrcode_thestorytellers.netlify.app.png
â”‚   â”œâ”€â”€ sign-up.html
â”‚
â”‚-- Model_and_Backend/
â”‚   â”œâ”€â”€ Gen_audio.py
â”‚   â”œâ”€â”€ Model.py
â”‚   â”œâ”€â”€ Sum_Dis.py
â”‚   â”œâ”€â”€ VPPP.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ readme.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”‚-- Notebook_Files/
â”‚   â”œâ”€â”€ Custom_Model_Resnet_Features.ipynb
â”‚   â”œâ”€â”€ Data_Downloader.ipynb
â”‚   â”œâ”€â”€ Feature_Extraction_Resnet50.ipynb
â”‚   â”œâ”€â”€ Feature_Extraction_VIT.ipynb
â”‚   â”œâ”€â”€ Readme.md
â”‚   â”œâ”€â”€ SpaceTimeGPT_FineTunining.ipynb
â”‚   â”œâ”€â”€ T5_Model.ipynb
â”‚   â”œâ”€â”€ Test_Models.ipynb
â”‚   â”œâ”€â”€ VIT_GPT2.ipynb
â”‚   â”œâ”€â”€ VIT_GPT2_Full_Pipeline.ipynb
â”‚
â”‚-- README.md  (This file)
```

---

## ğŸ“Œ Key Components

### 1ï¸âƒ£ FrontEnd
- **Description:** Contains the HTML files for the web-based user interface.
- **Files:**
  - `index.html` â†’ Main landing page.
  - `log-in.html` â†’ User authentication page.
  - `sign-up.html` â†’ User registration page.
  - `qrcode_thestorytellers.netlify.app.png` â†’ QR code for accessing the tool online.

### 2ï¸âƒ£ Model and Backend
- **Description:** Contains backend logic, models, and APIs.
- **Files:**
  - `Gen_audio.py` â†’ Converts text descriptions into **audio narrations**.
  - `Model.py` â†’ Contains the **core ML model** for video captioning.
  - `Sum_Dis.py` â†’ Summarizes generated captions for concise descriptions.
  - `VPPP.py` â†’ Video Pre-Processing Pipeline for structured data input.
  - `app.py` â†’ Flask-based backend API.
  - `requirements.txt` â†’ Dependencies and package requirements.

### 3ï¸âƒ£ Notebook Files
- **Description:** Contains Jupyter notebooks for training, testing, and optimizing models.
- **Notable Notebooks:**
  - `Data_Downloader.ipynb` â†’ Downloads video datasets from given URLs.
  - `Feature_Extraction_Resnet50.ipynb` â†’ Extracts **video features** using ResNet50.
  - `Feature_Extraction_VIT.ipynb` â†’ Extracts **video features** using Vision Transformer (VIT).
  - `Custom_Model_Resnet_Features.ipynb` â†’ Implements an **LSTM model** trained on ResNet50 features.
  - `VIT_GPT2.ipynb` â†’ Tests **VIT-GPT2 model** on sample videos.
  - `VIT_GPT2_Full_Pipeline.ipynb` â†’ End-to-end pipeline: caption generation, audio conversion, silent part detection, and final output.
  - `SpaceTimeGPT_FineTunining.ipynb` â†’ Fine-tunes SpaceTimeGPT for video captioning.

---

## ğŸŒŸ How It Works (STAR Approach)

### **SITUATION**
**Problem:** Many videos lack **accurate captions and audio descriptions**, making them inaccessible to visually and hearing-impaired users.

### **TASK**
- Develop an **automated captioning system** that generates high-quality text descriptions.
- Convert captions into **audio descriptions** for accessibility.
- Ensure synchronization between **audio and video**.
- Provide a **user-friendly web interface**.

### **ACTION**
âœ… Built an end-to-end **deep learning pipeline** using **Vision Transformer (VIT) and GPT-2**.  
âœ… Developed **LSTM-based models** to enhance caption accuracy.  
âœ… Integrated **Google TTS** for generating realistic audio descriptions.  
âœ… Used **Apache Airflow** to schedule and automate video processing.  
âœ… Designed an interactive **frontend** for seamless user interactions.

### **RESULT**
ğŸš€ **70% reduction in manual captioning efforts**.  
ğŸ¯ **Achieved a BLEU Score of 0.73**, indicating high-quality caption generation.  
ğŸ“ˆ **Improved video accessibility** for visually impaired users.

---

## ğŸ›  Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/jaivinjacob/Automated_Video_Captioning_Tool.git
cd Automated_Video_Captioning_Tool
```

### **2ï¸âƒ£ Set Up a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r Model_and_Backend/requirements.txt
```

### **4ï¸âƒ£ Run the Backend**
```bash
cd Model_and_Backend
python app.py
```

### **5ï¸âƒ£ Open Frontend in Browser**
Simply open `index.html` in a web browser.

---

## ğŸ¯ Future Improvements
- Enhance **caption accuracy** using **multi-modal transformers**.
- Improve **speech synthesis quality** for more natural narration.
- Develop an **API for third-party integration**.

---

## ğŸ“© Contact
For any queries or contributions, feel free to reach out:

ğŸ“§ Email: [jaivinjacobvj@gmail.com](mailto:jaivinjacobvj@gmail.com)  
ğŸ”— LinkedIn: [linkedin.com/in/jaivinjacob](https://linkedin.com/in/jaivinjacob)  
ğŸ’» GitHub: [github.com/JaivinJacob](https://github.com/JaivinJacob)

---

### ğŸŒŸ If you find this project useful, **give it a â­ on GitHub!** ğŸš€
